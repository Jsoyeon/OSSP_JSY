{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import pdb\n",
    "import re\n",
    "random_state = None\n",
    "import time\n",
    "starttime = time.monotonic()\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, StratifiedShuffleSplit\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#import unidecode\n",
    "from collections import defaultdict\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.preprocessing import FunctionTransformer, LabelEncoder\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_json('train.json')\n",
    "test = pd.read_json('test.json')\n",
    "\n",
    "train['num_ingredients'] = train['ingredients'].apply(lambda x: len(x))\n",
    "test['num_ingredients'] = test['ingredients'].apply(lambda x: len(x))\n",
    "train = train[train['num_ingredients'] > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "def preprocess(ingredients):\n",
    "    ingredients_text = ' '.join(ingredients)\n",
    "    ingredients_text = ingredients_text.lower()\n",
    "    ingredients_text = ingredients_text.replace('-', '')#wasabe\n",
    "    ingredients_text = ingredients_text.replace('wasabe', 'wasabi') #for wrong name\n",
    "    ingredients_text = ingredients_text.replace('egg whites', 'eggwhites , egg , whites')\n",
    "    ingredients_text = ingredients_text.replace('lime juice', 'limejuice')\n",
    "    ingredients_text = ingredients_text.replace('clam juice', 'clamjuice')\n",
    "    ingredients_text = ingredients_text.replace('lemon juice', 'lemonjuice')\n",
    "    ingredients_text = ingredients_text.replace('orange juice', 'orangejuice')\n",
    "    ingredients_text = ingredients_text.replace('soy sauce', 'soysauce')\n",
    "    ingredients_text = ingredients_text.replace('fish sauce', 'fishsauce')\n",
    "    ingredients_text = ingredients_text.replace('sesame oil', 'sesameoil')\n",
    "    ingredients_text = ingredients_text.replace('olive oil', 'oliveoil')#vegetable oil corn oil\n",
    "    ingredients_text = ingredients_text.replace('vegetable oil', 'vegetableoil')\n",
    "    ingredients_text = ingredients_text.replace('corn oil', 'cornoil')#rice wine\n",
    "    ingredients_text = ingredients_text.replace('coconut cream', 'coconutcream')\n",
    "    ingredients_text = ingredients_text.replace('yellow onion', 'yellowonion')\n",
    "    ingredients_text = ingredients_text.replace('cream cheese', 'creamcheese') \n",
    "    ingredients_text = ingredients_text.replace('baby spinach', 'babyspinach')\n",
    "    ingredients_text = ingredients_text.replace('coriander seeds', 'corianderseeds')\n",
    "    ingredients_text = ingredients_text.replace('corn tortillas', 'corntortillas')\n",
    "    ingredients_text = ingredients_text.replace('rice cakes', 'ricecakes')\n",
    "    words = []\n",
    "    for word in ingredients_text.split():\n",
    "        if re.findall('[0-9]', word): continue\n",
    "        if len(word) <= 2: continue\n",
    "        if 'â€™' in word: continue\n",
    "        word = lemmatizer.lemmatize(word)\n",
    "        if len(word) > 0: words.append(word)\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['ingredients_clean_string'] = [' , '.join(z).strip() for z in train['ingredients']]\n",
    "train['x'] = [' '.join([WordNetLemmatizer().lemmatize(re.sub('[^A-Za-z]', ' ', line)) for line in lists]).strip() for lists in train['ingredients']]       \n",
    "test['ingredients_clean_string'] = [' , '.join(z).strip() for z in test['ingredients']]\n",
    "test['x'] = [' '.join([WordNetLemmatizer().lemmatize(re.sub('[^A-Za-z]', ' ', line)) for line in lists]).strip() for lists in test['ingredients']]       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cuisine</th>\n",
       "      <th>id</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>num_ingredients</th>\n",
       "      <th>ingredients_clean_string</th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>greek</td>\n",
       "      <td>10259</td>\n",
       "      <td>[romaine lettuce, black olives, grape tomatoes...</td>\n",
       "      <td>9</td>\n",
       "      <td>romaine lettuce , black olives , grape tomatoe...</td>\n",
       "      <td>romaine lettuce black olives grape tomatoes ga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>southern_us</td>\n",
       "      <td>25693</td>\n",
       "      <td>[plain flour, ground pepper, salt, tomatoes, g...</td>\n",
       "      <td>11</td>\n",
       "      <td>plain flour , ground pepper , salt , tomatoes ...</td>\n",
       "      <td>plain flour ground pepper salt tomato ground b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>filipino</td>\n",
       "      <td>20130</td>\n",
       "      <td>[eggs, pepper, salt, mayonaise, cooking oil, g...</td>\n",
       "      <td>12</td>\n",
       "      <td>eggs , pepper , salt , mayonaise , cooking oil...</td>\n",
       "      <td>egg pepper salt mayonaise cooking oil green ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>indian</td>\n",
       "      <td>22213</td>\n",
       "      <td>[water, vegetable oil, wheat, salt]</td>\n",
       "      <td>4</td>\n",
       "      <td>water , vegetable oil , wheat , salt</td>\n",
       "      <td>water vegetable oil wheat salt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>indian</td>\n",
       "      <td>13162</td>\n",
       "      <td>[black pepper, shallots, cornflour, cayenne pe...</td>\n",
       "      <td>20</td>\n",
       "      <td>black pepper , shallots , cornflour , cayenne ...</td>\n",
       "      <td>black pepper shallot cornflour cayenne pepper ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cuisine     id                                        ingredients  \\\n",
       "0        greek  10259  [romaine lettuce, black olives, grape tomatoes...   \n",
       "1  southern_us  25693  [plain flour, ground pepper, salt, tomatoes, g...   \n",
       "2     filipino  20130  [eggs, pepper, salt, mayonaise, cooking oil, g...   \n",
       "3       indian  22213                [water, vegetable oil, wheat, salt]   \n",
       "4       indian  13162  [black pepper, shallots, cornflour, cayenne pe...   \n",
       "\n",
       "   num_ingredients                           ingredients_clean_string  \\\n",
       "0                9  romaine lettuce , black olives , grape tomatoe...   \n",
       "1               11  plain flour , ground pepper , salt , tomatoes ...   \n",
       "2               12  eggs , pepper , salt , mayonaise , cooking oil...   \n",
       "3                4               water , vegetable oil , wheat , salt   \n",
       "4               20  black pepper , shallots , cornflour , cayenne ...   \n",
       "\n",
       "                                                   x  \n",
       "0  romaine lettuce black olives grape tomatoes ga...  \n",
       "1  plain flour ground pepper salt tomato ground b...  \n",
       "2  egg pepper salt mayonaise cooking oil green ch...  \n",
       "3                     water vegetable oil wheat salt  \n",
       "4  black pepper shallot cornflour cayenne pepper ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = make_pipeline(\n",
    "    TfidfVectorizer(sublinear_tf=True),\n",
    "    FunctionTransformer(lambda x: x.astype('float16'), validate=False)\n",
    ")\n",
    "\n",
    "x_train = vectorizer.fit_transform(train['x'].values)\n",
    "x_train.sort_indices()\n",
    "x_test = vectorizer.transform(test['x'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'brazilian': 0,\n",
       " 'british': 1,\n",
       " 'cajun_creole': 2,\n",
       " 'chinese': 3,\n",
       " 'filipino': 4,\n",
       " 'french': 5,\n",
       " 'greek': 6,\n",
       " 'indian': 7,\n",
       " 'irish': 8,\n",
       " 'italian': 9,\n",
       " 'jamaican': 10,\n",
       " 'japanese': 11,\n",
       " 'korean': 12,\n",
       " 'mexican': 13,\n",
       " 'moroccan': 14,\n",
       " 'russian': 15,\n",
       " 'southern_us': 16,\n",
       " 'spanish': 17,\n",
       " 'thai': 18,\n",
       " 'vietnamese': 19}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(train['cuisine'].values)\n",
    "dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = SVC(C=260, # penalty parameter, setting it to a larger value \n",
    "\t \t\t\t kernel='rbf', # kernel type, rbf working fine here\n",
    "\t \t\t\t degree=3, # default value, not tuned yet\n",
    "\t \t\t\t gamma=1.4, # kernel coefficient, not tuned yet\n",
    "\t \t\t\t coef0=1, # change to 1 from default value of 0.0\n",
    "\t \t\t\t shrinking=True, # using shrinking heuristics\n",
    "\t \t\t\t tol=0.001, # stopping criterion tolerance \n",
    "\t \t\t\t probability=False, # no need to enable probability estimates\n",
    "\t \t\t\t cache_size=1000, # 200 MB cache size\n",
    "\t \t\t\t class_weight=None, # all classes are treated equally \n",
    "\t \t\t\t verbose=False, # print the logs \n",
    "\t \t\t\t max_iter=-1, # no limit, let it run\n",
    "\t \t\t\t decision_function_shape=None, # will use one vs rest explicitly \n",
    "\t \t\t\t random_state=None)\n",
    "classifier = OneVsRestClassifier(estimator, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=SVC(C=260, cache_size=1000, class_weight=None, coef0=1,\n",
       "  decision_function_shape=None, degree=3, gamma=1.4, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "          n_jobs=-1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cuisine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18009</td>\n",
       "      <td>irish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28583</td>\n",
       "      <td>southern_us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41580</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29752</td>\n",
       "      <td>cajun_creole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35687</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id       cuisine\n",
       "0  18009         irish\n",
       "1  28583   southern_us\n",
       "2  41580       italian\n",
       "3  29752  cajun_creole\n",
       "4  35687       italian"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = label_encoder.inverse_transform(classifier.predict(x_test))\n",
    "test['cuisine'] = y_pred\n",
    "test[['id', 'cuisine']].to_csv('0111_plus.csv', index=False)\n",
    "test[['id', 'cuisine']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
