{
  "cells": [
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d0c71f50fcbec84e95f563aecea8d65a42162d08"
      },
      "cell_type": "code",
      "source": "from pandas import Series, DataFrame\nimport pandas as pd\nimport numpy as np\nimport nltk\nimport re\nfrom nltk.stem import WordNetLemmatizer\nfrom sklearn.svm import LinearSVC\nfrom sklearn.metrics import classification_report\nimport sklearn.metrics\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LogisticRegression",
      "execution_count": 96,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "61a40939b8fb7875cb9e8744b2fb0a3b0eaa393b"
      },
      "cell_type": "code",
      "source": "# load data file into Python\ntrain = pd.read_json(\"../input/train.json\")\ntest = pd.read_json(\"../input/test.json\") \n\n# clean data\ntrain['ingredients_clean_string'] = [' , '.join(z).strip() for z in train['ingredients']]  \ntest['ingredients_clean_string'] = [' , '.join(z).strip() for z in test['ingredients']]\n\n# further clean data and extract information through word lemmatization\ntrain['ingredients_string'] = [' '.join([WordNetLemmatizer().lemmatize(re.sub('[^A-Za-z]', ' ', line)) \n                                         for line in lists]).strip() for lists in train['ingredients']]       \ntest['ingredients_string'] = [' '.join([WordNetLemmatizer().lemmatize(re.sub('[^A-Za-z]', ' ', line)) \n                                          for line in lists]).strip() for lists in test['ingredients']]       \n",
      "execution_count": 97,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f88b80bab9f3f717572c913911ab91c6dac7fe10"
      },
      "cell_type": "code",
      "source": "# create corpus based on newly processed data\ntrain_corpus = train['ingredients_string']\ntest_corpus = test['ingredients_string']\n\n# convert a collection of raw documents to a matrix of TF-IDF features\ntrain_vectorizer = TfidfVectorizer(stop_words='english',\n                             ngram_range = ( 1 , 1 ),analyzer=\"word\", \n                             max_df = .57 , binary=False , token_pattern=r'\\w+' , sublinear_tf=False)\ntest_vectorizer = TfidfVectorizer(stop_words='english')\n\n# transform the corpus to a dense matrix representation\ntrain_tfidf=train_vectorizer.fit_transform(train_corpus).todense()\ntest_tfidf=train_vectorizer.transform(test_corpus)",
      "execution_count": 98,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6be5c97fcc98bbc3749c992b7ab6948f365008a5"
      },
      "cell_type": "code",
      "source": "# prepare data for prediction\ntrain_predictor = train_tfidf\ntest_predictor = test_tfidf\n\ntrain_target = train['cuisine']\n\n\n# build Linear Support Vector Classification model\n# set penalty parameter as 0.8 with standard penaliation l2\n# select the algorithm to solve primal optiomization problem\nclassifier = LinearSVC(C=0.80, penalty=\"l2\", dual=False)\n\n# model = LinearSVC()\nmodel = LogisticRegression()\n\n# process exhaustive search over specified parameter values for the model\nparameters = {'C':[1, 10]}\nclassifier = GridSearchCV(model, parameters)\n\n",
      "execution_count": 100,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "17815af8fc4adc948c34b2c4385d82b8c5b4ec6e"
      },
      "cell_type": "code",
      "source": "# fit classification model to data\nclassifier=classifier.fit(train_predictor,train_target)\n\n# make prediction\nprediction=classifier.predict(test_predictor)\n\n# assign predicted values to cuisine in TEST set\ntest['cuisine'] = prediction\n\n# write csv file (no index for submission)\ntest[['id','cuisine' ]].to_csv(\"0108_3_v8.csv\",index=False)",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n  warnings.warn(CV_WARNING, FutureWarning)\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ee4a2081efea1d13cbce61709b6b02a8d4cca99e"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}